=== Kubernetes - Desired State Management 

Kubernetes (K8s) is an open-source system for automating deployment, scaling,
and management of containerized applications.

    K8's cluster Services 
    kubnet Workers 

    pod - Smallest unit of deployment - One or multiple running containers / Image details and Replicas information.
    *Can have multiple pods 
    A Kubernetes pod is a group of containers that are deployed together on the same host. If you frequently deploy 
    single containers, you can generally replace the word "pod" with "container" and accurately understand the concept

    Kubernetes Features :

        - Service discovery and load balancing
        - Automatic bin packing
        - Storage orchestration
        - Self-healing
        - Automated rollouts and rollbacks
        - Secret and configuration management
        - Batch Execution
        - Horizentol Scaling


Docker is a platform and tool for building, distributing, and running Docker containers. ... 
Kubernetes is a container orchestration system for Docker containers that is more extensive 
than Docker Swarm and is meant to coordinate clusters of nodes at scale in production in an efficient manner.

===== Create Cluster 

Kubernetes coordinates a highly available cluster of computers that are 
connected to work as a single unit.

A Kubernetes cluster consists of two types of resources:
    -   The Master coordinates the cluster
    -   Nodes are the workers that run applications

Minikube - Minikube is a tool that makes it easy to run Kubernetes locally. 
Minikube runs a single-node Kubernetes cluster inside a Virtual Machine (VM)



    minikube version
    
    minikube start 





==== Pre Requisite 
    - Windows Powershell (For Windows) (Version >=5.1)
    - Enable NotePad for vi commands. 
        new-alias vi notepad 

      The above command will enable Powershell to use notepad editor anytime we run "vi" command.

    

==== Conternazation with Kubernetes -
A container is defined as a collection of software processes unified
by one namespace with access to an operating system kernel that it shares
with other containers and little or no access between them.

=====   Kubernetes -
the most popular open-source container orchestrator available today. 

Container Orchestartion

Orchestration Features:
    - Provision Hosts
    - Instantiate containers on a host 
    - Restart Failing containers 
    - Expose containers as services outside the cluster



DEFINATION - Kubernetes is an open-source platform designed to automate the deployment, scaling, 
and operation of containers.

GOAL - The real goal of the platform is to foster an ecosystem of
components and tools that relieve the burden of running applications in public and private clouds.

Kubernetes, often called K8S or Hubernetes, is an open-source platform that started at Google.

Kubernetes and Docker :
Kubernetes is a container Platform. You can use Docker Containers to develop and build applications and then use
Kubernetes to run these applications on your infrastructure.


===== Kubernetes Features 

    - Multi-Host Container Schedule
        - Done by the kube-scheduler
        - Assigns pods to nodes at runtime
        - Check resources, quality of service, policies, and user specifications before scheduling

    - Scalability and avalability 
        -   5000 nodes clusters 

    - Flixiblity and modularity 
        - Service discovery 

    - Registration and discovery (Service discovery)
    - Persistant Storage 
    - Application Upgrades and maintanence 
    - Logging and Monitering 
    - Secret Management 


    Major Players in Container Orchestartion landscape today are:
        - Kubernetes
        - Docker Swarm 
        - Rancher 
        - Mesos 

    Also, some cloud specific technologies 
        - Amazon EC2 Container 
        - Google cloud 



===== Docker Swarm 
-   Docker Swarm is responsible for clustering and scheduling containers across hosts. 
-   It's a simpler architecture when compared to Kubernetes and Mesos. 
-   It is written in golang and it's a lightweight, declarative language. 
-   It's easy to get started, setup and understand. 
-   The typical users of Docker Swarm are smaller teams, like startups and medium-size companies. 
-   And I've only seen Swarm used in brand new greenfield projects. Which are driven by teams that are mostly
    developers who need to deploy new products. 
    

*Greenfield Projects 
*Brownfield Projects 


===== Mesos 
-   Mesos on the other hand is written in C++, with APIs in Java, Python, and C++. 
-   It's the oldest tool of the bunch, but this also means that it's the most stable.
-   Mesos has a distributed kernel where many machines end up acting like one logical entity. 
-   The Marathon framework can be added to Mesos to schedule and execute tasks. And finally, 
-   Mesos has a more complex architecture than Docker Swarm. The typical users of Mesos are 
    larger enterprises that require lots of compute, or jobs/task-oriented workloads. 
-   Mesos is often used by companies that have to perform big data jobs. I've also seen 
-   Mesos being driven more by developers rather than operations, but you require an 
    operations team to manage the tool. 

 ===== Rancher 
-   Rancher is a full stack container management platform.
-   Initially it used to use a custom cluster orchestrator called cattle 
    but now it suppers Kubernetes and Docker Swarm. 
-   It was an early player in the Docker ecosystem and had orchestration concepts that were way before 
    its time and way before they were a hot topic. It has a great user interface
    and API to interact with clusters and provides enterprise support for its tooling. 
-   One of the other benefits of Rancher is that it supports organizations and teams out of box. 
    The typical Rancher users are smaller teams, think startups or medium-sized companies. 
    And most of the Rancher users I've seen are developer-driven teams who need to deploy products quickly.
    Or they're dev-ops teams that need to manage an agile infrastructure.
    
    This chart plots the number of hosts and containers versus the size of the development team

             ^                              Kubernetes
   Size      |                              Mesos 
    Of       |               Docker Swarm 
    Team     |            Rancher 
             |        Nomad
             ------------------------------------------------------------->
                Numbers of Hosts/Containers 
    




=== Kubernetes Terminology

==== Kubernetes architecture

===== Master Node :
Responsible for overall management of Kubernetes Cluster. It has got three componenent that takes care of 
Communication, Scheduling, and controllers using  Kube API Server, Schedular, Controller Manager.

Kube API Server - allows you interact with Kubernets API. Front end of kubernete control pane.

Schedular - It watches created PODs who does not have node design yet, and designs the POD to run on a specific node.
Physically schedules pods based on the criteria provided across all the nodes 

Controller Manager - Runs controllers. The contoller actually has bunch of different roles, and it acts as a single binary.

    - The Node Controller - Workers states
    - The Deployment Controller -
    - The Replication Controller - Maitaining the correct number of pods
    - The End-Point Controller - Which joins Services and Pods together 
    - Service Account and Token Controller - Handles Access Management 

etcd - Simple Distributed Key Value Store. Acts as DB which stores all cluster data here. 
        Some of the information that might be stored is Job Scheduling info, Pod Details, Stage infromation etc.
        Store current state of the cluster 


kubectl - A command line interface for kubernetes which allows you to interact with Master Node. kubectl 
        have a config file caled kubeconfig. This file has server information as well as authentication 
        information to access to API Server.


===== WORKER NODE :
Worker Nodes are the nodes where your applications operate. The Worker node communicate back with the Master nodes.
And this communication is handled by the Kubelet Process.
           
- kubelete - Its an agent that communicate with API Server, and it is designed to see if 
                    Pods have been designed to the NODES. It executes the POD containers via the container engine.
                    It mounts and runs POD volumes and secrets, and finally it is aware of Pods and Nodes States,
                    and responsd back to the Master.

- Docker - To run containers on the node we have DOCKER. We could use alternate container platforms as well.

- kube-proxy - Network Proxy and load balancer for the service on a single worker node. It handles the network
                routing for TCP and UDP Packets, and performs connection forwarding.
                A pod is a smallest unit that can be scheduled as a deployment in Kubernetes. This 
                group of containers share storage, Linux namespace, IP Addresses, amongst other things.
                
    Once the pod is deployed, the kubelete process communicate with pods to check on health and
    state. And the kube-proxy routes any packets to the PODS from other resources.

    Worker Nodes can be exposed to the internet via load balancer. The traffic coming in would be handled by 
    kube-proxy, and this is how an end-user ends up taking to a Kubernetes Application.





===== Basic Building Blocks

    - NODE: The node serves as a worker machine in a K8s cluster. One important thing to note is that 
        the node can be a physical computer or a virtual machine. Node must have following requirements.
        - Node must have A kubelet running 
        - Container tooling like Docker 
        - A kube-proxy process running 
        - Supervisored - so it can restart components.

    ** Recommendation - if you are using Kubernetes in production, it is typically recommended to have at least a three-node cluster.

    ** Minikube - lightweight kubernetes implementation that creates a VM on your local machine and deploys simple 
        cluster containing only one node.

    You applications runs on node. 

    - POD - The Simplest unit that can ineract with you. You can create, deploy and delete pods, and it represent one running process 
            on your cluster.
            Pods is a scheduling unit in Kubernetes.
            A Pod is the basic execution unit of a Kubernetes application
    
    A Kubernetes Pod is a group of one or more Containers, tied together for the purposes of administration 
    and networking.

    Service - An abstract way to expose an application running on a set of Pods as a network service.



    - Whats in the POD 
        - Your docker application container 
        - Storage Resources 
        - Unique Network IP 
        - Options that govern how the container should run. 

    In some scenarios you can have multiple containers running in a Pod, but a pod represents one single unit
    of deployment, a single instance of an application in kubernetes thats tightly coupled and shared resources.

    PODS are ...
        - Empheral, disposable 
        - Never self-heal and not restarted by the scheduler by itself.
        - Never create Pods just by themselves
        - Always use high-level constructs (Use a controller instead for deployments)

    POD States 
        - Pending : Pod has been accepted from kubernetes system, but a container has not been created yet.
        - Running : A Pod has been scheduled on a Node, and all of its containers are created, and at least one 
                    container is in a running state.

        - Succeeded : All the containers in a pod have exited with an exit status of Zero and will not be restarted.

        - Failed : All the containers in the pod have exited and at least one container has failed and return 
                a non zero exit status.

        - CrashLoopBackOff - This is where containe fails to start for some reason, and kubernetes tries over 
                            and over and over again to restart the pod. 


===== Deployments, RaplicaSets, and Services

- Deployment Controller - It provides declarative updates for PODS and ReplicaSets.
    It internally manages the POD using Replica Sets.

- Replicasets - Ensures that a specified number of replicas for a pod are running at all times.

- DaemonSets - Ensures that all nodes run a copy of specified pod.
- Services 


===== Labels, Selectors and Namespaces 

- Labels

- Selectors :
    - Equality-Based - EQUALS and NOT EQUALS 
    - Set-Based - IN, NOTIN or EXIST Operators (Check value in defined set of values )

- Namespaces :



===== Kubelet and Kube Proxy

- Kubelet - The kubelet is the "Kubernets node agent" that runs on each node.

-Kubelet Roles:
    - Communication with API server to see if pods have been assigned to nodes.
    - Executes pod containers via a container engine 
    - Mounts and runs pod volumnes and secrets
    - Executes health checks to identify pod/node status.

The kubelet works in terms of Podspec. Podspec is a YAML file describes a POD.
The kubelet takes a set of Podspecs that are provided by the kube-apiserver and ensures 
that the containers described in thoes podeSpecs are running and healthy.
Kubelet only manages containers that are created by the API server - Not any container running on the node.


- Kube-proxy 
    - Network Proxy is called kube-proxy
    - Process that runs on all worker nodes 

Three Modes of kube-proxy 
    - User space mode - The most common one 
    - Iptables mode 
    - ipvs mode (Alpha feature)

Why these modes are important

    - These modes are important when it comes to using services.
    - Services are defined against the API Server: kube-proxy watches the SPI Server for the 
        addition and removal of services.
    - For each new services, kube-proxy opens a randomly chosen port on the local node.
    - Connection made to the chosen port are proxied to one of the corresponding back-end pods.



==== Geting Up and Running Kubernetes on Windows 

1. Install Docker latest version
2. Insall Hyper V (Its already installed on Windows Machine) 
    We need to make soe configuration changes here.

    We need to create new Virtual Network Switch. For that:
    1. Open "Hyper-v Manager" and Go to Virtual Switch Manager
    2. Select "Internal" 
    3. Click on create Virtual Switch 
    4. Give some name to the switch, for example "Minikube"
    5. Select Internal Network from Radio Button option 
    6. Click on "Ok"

    Thats it. We have created a new virtual switch.

    To Enable the newly created switch 

    1. Go to Control Panel
    2. Search for "Network and Sharing Center"
    3. In the view your active networks Right hand side, you will find Connections "Ethernet"
    4. Click on "Properties" 
    5. Click on "Sharing"
    6. Check the box "Allow other network users to connect through this computers inernet connection"
    7. In the drop down of "Home Networking Connection" select "vEthernet Minikube" (the one we have created in above Section)
    8. Click on "Ok"        

    Virtual Switch - A virtual switch is a software program that allows one virtual machine (VM) to 
    communicate with another. Just like its counterpart, the physical Ethernet switch, a virtual switch
    does more than just forward data packets.


3. Install Kubectl 
    * Download link: https://kubernetes.io/docs/tasks/tools/install-kubectl/#install-kubectl-binary-via-curl

4. Install Minikube 
    * General Download Instructions: https://kubernetes.io/docs/tasks/tools/install-minikube/
    * Download link: https://github.com/kubernetes/minikube/releases

    Minikube : Minikube is a tool that makes it easy to run Kubernetes locally. 
    Minikube runs a single-node Kubernetes cluster inside a Virtual Machine (VM) on your 
    laptop for users looking to try out Kubernetes or develop with it day-to-day.



5. Once both are downloaded, we need to copy kubectl and minikube executables in a folder and add that folder in 
    Environment Variable 


        docker version
        kubectl version
        minikube version 

    ** Kindly ensure to run all these commands in Windows Power Shell command prompt.


6. Start the minikube 

For Windows: 
    minikube start --kubernetes-version="v1.8.0" --vm-driver="hyperv" --hyperv-virtual-switch="Minikube"

For Mac or Linux:
    minikube start  
    
    minikube clear 

    minikube stop 



7. Once installation finished, to ensure kubectl is up and running 
    
    kubectl get pods
    kubectl get nodes 
    kubectl get deployments 
    kubectl get rs   (rs - ReplicaSet )

Also, go to HyperV Manager, you will see "Minikube" in available virtual machines list.


This is all required to setup kunernetes in Windows machine.


==== Running a First Hello World Application 

minikube start 

    - It will setup a virtual box for us 

kubectl get nodes 
    - List of the nodes that are running 


kubectl run hw --image=karthequian/helloworld --port=80
    - Starts up a deployement 

kubectl get deployments 
    - List the deployment and its status 

kubeclt get rs 
    - To get the replica set details (Same as Deployment)

kubectl get pods 
    - Returns the Pod details 

kubectl expose deployment hw --type=NodePort 
    - Expose the deployed service 

kubectl get services 


minikube service <service-name>
minikube service hw 
    - It will open the service in browser 

kubectl get all 
    - It will returns all the details such as  pods, services, deployments, replicaset 
    - In other words, it will return all the resources running on ecosystem.

kubectl get deploy/hw -o yml 
    - It will returns deployment YML configuration 



kubectl create -f hello-world-deployment-all.yml 
        - Create service and deployment from YAML configuration 

To check both service and deployment created 
    kubectl get all 
    OR 
    kubectl get deployment 
    kubectl get service 

    SAMPLE YAML FILE :

    apiVersion: apps/v1beta1
    kind: Deployment
    metadata:
    name: helloworld-all-deployment
    spec:
    selector:
        matchLabels:
        app: helloworld
    replicas: 1 # tells deployment to run 1 pods matching the template
    template: # create pods using pod definition in this template
        metadata:
        labels:
            app: helloworld
        spec:
        containers:
        - name: helloworld
            image: karthequian/helloworld:latest
            ports:
            - containerPort: 80
    ---
    apiVersion: v1
    kind: Service
    metadata:
    name: helloworld-all-service
    spec:
    # if your cluster supports it, uncomment the following to automatically create
    # an external load-balanced IP for the frontend service.
    type: LoadBalancer
    ports:
    - port: 80
        protocol: TCP
        targetPort: 80
    selector:
        app: helloworld



===== Scaling the APP 
  
    kubectl get rs 
        - List all the replica details (Deployments) - Single POD 

    kubectl scale --replicas=3 deploy/helloworld-deployment
        - Here deploy/helloworld-deployment  is the existing deployment 
        - replicas=3 means it will create 3 PODS for the deployment of the application 

    kubectl get deploy/helloworld-deployment 
        - Give the list of the replicas running for that app 

    kubectl get pods 
        - List all the pod details 

    kubectl create -f <yaml-file-name>
        - Create POD

    Sample YML :
        appVersion: v1
        kind: Pod 
        metadata: 
            name:app-pod 
            tier:dev
        spec:
            containers:
                -name:nginx-container
                image:nginx 

    kubectl get pod 
        - List all the pods 

    kubectl get pod -o wide 
        - To show more details (The wide output option passed)

    kubectl get pod nginx-pod -o yaml 
        - Would display the Yaml file details 

    kubectl descrive pod <pod-name>
        - Would list all the details about the pod 

    kubectl exec -it <pod-name> -- /bin/sh 
        - To access the POD using bash 

    kubectl delete pod <pod-name>
        - Delete the pod 


=== Make it Production Ready 


==== Add Lables in POD 

    Sample POD File: 
        
        apiVersion: v1
        kind: Pod
        metadata:
        name: helloworld
        labels:
            env: production
            author: karthequian
            application_type: ui
            release-version: "1.0"
        spec:
        containers:
        - name: helloworld
            image: karthequian/helloworld:latest



    kubectl create -f <yaml.yml>

    kubeclt get pods 
        - List all the pods 

    kubectl get pods --show-labels 
        - List the pod with all the label details 

    kubectl get pods -o wide 
        - Also show the wider details of the pod 

    kubectl label  <pod-name> <new-label-name>=<label-value> --overwrite 

    kubectl label po/helloworld app=helloworldapp --overwrite 
        - Will create/update label of running PODS 


    kubectl label po/helloworld app- 
        - To Delete Label named app 

    kubectl get pods --show-label 
        - List all the labels 
        

===== Working with labels 

instead of "--selector", we could use shortcut "-l" 

kubectl get pods -l env=production
kubectl get pods --selector env=production
    - Filter and show only the label having env set to production     

kubectl get pods -l env!=production
kubectl get pods --selector env!=production
        - Filter and show only the label having env is not production     

kubectl get pods -l env=production, author=bhopal
kubectl get pods --selector env=production, author=bhopal
        - Filter and show only the label having env is production and author is bhopal     

kubectl get pods -l 'release-version in (1.0,1.2)'
kubectl get pods --selector  'release-version in (1.0,1.2)'
        - Filter and show only the label release version in 1.0 or 1.2     

kubectl get pods -l 'release-version notin (1.0,1.2)'
        - Filter and show only the label release version not in 1.0 and 1.2     

kubectl delete pods -l dev-lead=karthik 
    - Delete all the pods with Dev Lead Karthik Label 

    
===== Application Health Check 
We can add below configuration in YAML file to check the readiness and liveness 
readinessProbe:  
     length of time to wait for a pod to initialize
     after pod startup, before applying health checking
livenessProbe:
     length of time to wait for a pod to initialize
     after pod startup, before applying health checking
        

kubectl descrive po/<pod-name>
    - To check for the more details of the POD 


SAMPLE YML with PROBES :

        apiVersion: apps/v1beta1
        kind: Deployment
        metadata:
        name: helloworld-deployment-with-probe
        spec:
        selector:
            matchLabels:
            app: helloworld
        replicas: 1 # tells deployment to run 1 pods matching the template
        template: # create pods using pod definition in this template
            metadata:
            labels:
                app: helloworld
            spec:
            containers:
            - name: helloworld
                image: karthequian/helloworld:latest
                ports:
                - containerPort: 80
                readinessProbe:
                # length of time to wait for a pod to initialize
                # after pod startup, before applying health checking
                initialDelaySeconds: 10
                # Amount of time to wait before timing out
                initialDelaySeconds: 1
                # Probe for http
                httpGet:
                    # Path to probe
                    path: /
                    # Port to probe
                    port: 80
                livenessProbe:
                # length of time to wait for a pod to initialize
                # after pod startup, before applying health checking
                initialDelaySeconds: 10
                # Amount of time to wait before timing out
                timeoutSeconds: 1
                # Probe for http
                httpGet:
                    # Path to probe
                    path: /
                    # Port to probe
                    port: 80

===== Rollback and History of Deployments 

SAMPLE YML :

    apiVersion: apps/v1beta1
    kind: Deployment
    metadata:
    name: navbar-deployment
    spec:
    selector:
        matchLabels:
        app: helloworld
    replicas: 3 # tells deployment to run 3 pods matching the template
    template: # create pods using pod definition in this template
        metadata:
        labels:
            app: helloworld
        spec:
        containers:
        - name: helloworld
            image: karthequian/helloworld:black
            ports:
            - containerPort: 80
    ---
    apiVersion: v1
    kind: Service
    metadata:
    name: navbar-service
    spec:
    # if your cluster supports it, uncomment the following to automatically create
    # an external load-balanced IP for the frontend service.
    type: NodePort
    ports:
    - port: 80
        protocol: TCP
        targetPort: 80
    selector:
        app: helloworld



kubectl create -f <ymlfile.yml>  --record
    - Will start the deployement and service 

kubeclt get deployments 
    - List the deployements 

kubectl set image deployments/<deployment-name> helloworld=<new-image-name>
    - It will automaticall replace the deployed image 

kubectl get rs 
    - List out replica sets 

kubectl rollout history deployment/<name-of-the-deployment> 
    - List out all the history/commands assocaited with this deployment.

kubectl rollout undo deployment/<name-of-the-deployment> 
    - It will rollout/revert latest deplpoyment 

kubectl rollout undo deployment/<name-of-the-deployment> --to-revision=<revision-number>
    - rollout/revert the deployment to specific deployed configuration 




===== Basic Troubleshooting Techniques 

kubectl describe deployment <deployment-name>
    - List out detail logs of the selected deployment - For introspetion of the details 

kubectl describe po/<pod-name> 
    - List out the detail logs of the selected POD - For introspetion of the details 

OR 

kubectl logs <pod-name> 
    - List out all the running logs of this pod 

OR 

We can exec into specific POD 

kubectl exec -it <pod-name> /bin/bash
    - It will let you access the bash of POD 

Once you are into the pod, we can check all the running processes 

#root@hello-world:/# ps -ef 


kubectl exec -it <pod-name> -c <container-name> /bin/bash
    - If we have multiple containers inside the POD 



==== Advance Kubernetes 


===== Kubernetes Dashboard 

$ minikube addons list
    - addon-manager: enabled
    - dashboard: enabled
    - default-storageclass: enabled
    - efk: disabled
    - freshpod: disabled
    - gvisor: disabled
    - heapster: disabled
    - ingress: disabled
    - logviewer: disabled
    - metrics-server: disabled
    - nvidia-driver-installer: disabled
    - nvidia-gpu-device-plugin: disabled
    - registry: disabled
    - registry-creds: disabled
    - storage-provisioner: enabled
    - storage-provisioner-gluster: disabled

It will list all the addons 

Since the dashboard is already enabled in listed addons so we can simply open it by:
$ minikube dashboard 
    - It will open a browser and render kubernetes cluster dashboard 

heapster - To see cluster and CPU Memory 

$ minikube addons enable heapster 

Once enabled, to see the status. (We need to specify namespace here as heapster runs of different namespace. 
The namespace called "kube-system")
$ kubectl get pods --all-namespaces



===== Configmap
ConfigMaps allow you to decouple configuration artifacts from image 
content to keep containerized applications portable. 


====== Create a ConfigMap Using kubectl create configmap

To Send Dynamic Values to the config map 
Use the kubectl create configmap command to create configmaps from 
  
    - directories
        kubectl create configmap game-config --from-file=configure-pod-container/configmap/

    - files 
        kubectl create configmap game-config-2 --from-file=configure-pod-container/configmap/game.properties

  
    - literal values
        kubectl create configmap special-config --from-literal=special.how=very --from-literal=special.type=charm


    kubectl create configmap <map-name> <data-source>

    kubectl get configmaps <map-name> -o yaml
        - To see the config map details 

Applications require a way for us to pass data to them that can be changed at deploy time. Examples of this might be log-levels or urls of external systems that the application might need at startup time. Instead of hardcoding these values, we can use a configmap in kubernetes, and pass these values as environment variables to the container.
We will take an example of "log_level", and pass the value "debug" to a pod via a configmap in this example.

To create a configmap for this literal type `kubectl create configmap logger --from-literal=log_level=debug`
To see all your configmaps: `kubectl get configmaps`
To read the value in the logger configmap: `kubectl get configmap/logger -o yaml`
To edit the value, we can run `kubectl edit configmap/logger`

EXAMPLE :

    kubectl create configmap special-config --from-literal=special.how=very

        apiVersion: v1
        kind: Pod
        metadata:
        name: dapi-test-pod
        spec:
        containers:
            - name: test-container
            image: k8s.gcr.io/busybox
            command: [ "/bin/sh", "-c", "env" ]
            env:
                # Define the environment variable
                - name: SPECIAL_LEVEL_KEY
                valueFrom:
                    configMapKeyRef:
                    # The ConfigMap containing the value you want to assign to SPECIAL_LEVEL_KEY
                    name: special-config
                    # Specify the key associated with the value
                    key: special.how
        



=== Service 
Kubenetes Service is an abstraction of a logical set of pods. Simply service acts as 
an intermediate which allows pods to talk to each other. Kubernetes service also supports 
TCP and UDP protocols. You can point the set of pods need to expose from the Service you write. 

==== Types of Kubernetes services
    ClusterIP
    NodePort
    LoadBalancer

===== ClusterIP: 
This is the default service type available in Kubernetes. The service is reachable or visible 
only inside the cluster. If you do not want to expose your pod to the outside world, this is the 
correct service type. For an example, you don’t want to expose your database to the internet. 
You can only expose to the cluster pods using ClusterIP.

===== NodePort: 
When you want to expose your application to the internet, you can use this service type. 
Kubernetes master will provide a random port within the range 30000–32767 or you can provide 
a range using --service-node-port-range flag. Every kubernetes node will expose this port.

===== LoadBalancer: 
You can use this service type to provision a load balancer for your service. Some cloud providers allow the 
loadBalancerIP to be specified in the service yaml file. In those cases, the load-balancer will be created 
with the user-specified loadBalancerIPotherwise, an ephemeral IP will be assigned to the loadBalancer.     

    kind: Service
    apiVersion: v1
    metadata:
    name: my-service
    spec:
    selector:
        app: myapp
    ports:
    - protocol: TCP
        port: 443
        targetPort: 9095
    type: LoadBalancer



===== Dealing with Application Secret 
Kubernetes secret objects let you store and manage sensitive information, such as passwords, OAuth tokens, 
and ssh keys. Putting this information in a secret is safer and more flexible than putting it verbatim in 
a Pod definition or in a container image

The kubectl create secret command packages these files into a Secret and creates the object on the Apiserver.

Create Secret from file 
    -   kubectl create secret generic db-user-pass --from-file=./username.txt --from-file=./password.txt


    kubectl get secrets

    kubectl describe secrets/db-user-pass

Create Secret from Generator 
   

Create Secret from YAML  
 # Create a kustomization.yaml file with SecretGenerator
    $ cat <<EOF >./kustomization.yaml
    secretGenerator:
    - name: db-user-pass
    literals:
    - username=admin
    - password=secret
    EOF


Create Secret from String Literal 

    kubectl create secret generic <secret-name> --from-literal <key>=<value> 
    kubectl create secret generic apikey --from-literal api_key=1234


### Understand how to add a secret to a deployment
Adding a secret to a deployment is similar to what we did for configmaps. You can add a secret to the env 
portion, and start up the deployment with:

    `kubectl create -f secretreader-deployment.yaml`


      YAML FILE:
        apiVersion: extensions/v1beta1
        kind: Deployment
        metadata:
        name: secretreader
        spec:
        replicas: 1
        template:
            metadata:
            labels:
                name: secretreader
            spec:
            containers:
            - name: secretreader
                image: karthequian/secretreader:latest
                env:
                - name: api_key
                valueFrom:
                    secretKeyRef:
                    name: apikey
                    key: api_key  


===== Running Jobs in kubernetes 
# Jobs in Kubernetes

## Chapter Goals
1. How to run jobs
2. How to run cron jobs

### How to run jobs
Jobs are a construct that run a pod once, and then stop. However, unlike pods in deployments, the output of the job is kept around until you decide to remove it.

Running a job is similar to running a deployment, and we can create this by `kubectl create -f simplejob.yaml`

    apiVersion: batch/v1
    kind: Job
    metadata:
    name: pi
    spec:
    template:
        spec:
        containers:
        - name: pi
            image: perl
            command: ["perl",  "-Mbignum=bpi", "-wle", "print bpi(2000)"]
        restartPolicy: Never
    backoffLimit: 4


To see the output of the job: `kubectl get jobs`

You can find the pod that ran by doing a `kubectl get pods --all-pods`, and then get the logs from it as well.

### How to run cron jobs
Cron jobs are like jobs, but they run periodically.

Start your cron by running `kubectl create -f cronjob.yaml`

We can use the cronjob api to view your cronjobs: `kubectl get cronjobs`. It adds the last schedule date

 YAML :

    apiVersion: batch/v1beta1
    kind: CronJob
    metadata:
    name: hellocron
    spec:
    schedule: "*/1 * * * *" #Runs every minute (cron syntax) or @hourly.
    jobTemplate:
        spec:
        template:
            spec:
            containers:
            - name: hellocron
                image: busybox
                args:
                - /bin/sh
                - -c
                - date; echo Hello from your Kubernetes cluster
            restartPolicy: OnFailure #could also be Always or Never
    suspend: false #Set to true if you want to suspend in the future


 kubectl get jobs 


=== Running Stateful Set applications 

===== DaemonSet 
A DaemonSet ensures that all (or some) Nodes run a copy of a Pod. As nodes are added to the cluster, 
Pods are added to them. As nodes are removed from the cluster, those Pods are garbage collected. 
Deleting a DaemonSet will clean up the Pods it created.

A DaemonSet ensures that all Nodes run a copy of a Pod. As nodes are added to the cluster, 
Pods are added to them. Examples of a daemon set would be running your logging or monitoring agent on your nodes.


Some typical uses of a DaemonSet are:

running a cluster storage daemon, such as glusterd, ceph, on each node.

running a logs collection daemon on every node, such as fluentd or logstash.

running a node monitoring daemon on every node, such as Prometheus Node Exporter, Sysdig Agent, collectd, 
Dynatrace OneAgent, AppDynamics Agent, Datadog agent, New Relic agent, Ganglia gmond or Instana Agent.



Zookeeper 
Sticky Session 

====== StatefulSet 
StatefulSet is the workload API object used to manage stateful applications.

Statefulsets Manages the deployment and scaling of a set of Pods, and provides guarantees about the 
ordering and uniqueness of these Pods. Unlike a Deployment, a StatefulSet maintains a sticky identity 
for each of their Pods.

StatefulSets are valuable for applications that require one or more of the following.
    Stable, unique network identifiers.
    Stable, persistent storage.
    Ordered, graceful deployment and scaling.
    Ordered, automated rolling updates.


=== Persistent Volume (PV) and Persistent Volume Claim (PVC)

Different Persistent storage type such as Block Storage, NFS, Object Storage, Others 

Persistent Volumes - It provides standard APIs to access all types of storage types 

Abstract details of how storage is provided from how it is consumed.

    - Persistent Volume (PV) - - (Piece of storage in Clusters)
        - Provisioned by Admin.
        - Data available beyond life cycle of POD 

    - Persistent Volume Claim (PVC) (Request for Storage)
        - Developer request for storage for READ/WRITE works 
        
==== Lifecycle of a Persistent Volume 
    
    - Provisioning 
        Static - PV needs to be created before PVC  - Kind "PersistentVolume"
        Dynamic - PV is created at same time of PVC - Kind "StorageVolume"

    - Binding (also called Claiming)
        Get Vloume using PVC 
    - Using 
        Use into the POD as a volume 
    - Reclaiming
        - Delete the volume once user is done with the work 


    kubectl get pv 
    kubectl get pvc 

    REFERENCE - https://www.youtube.com/watch?v=XSNuDl3wHuc&list=PLMPZQTftRCS8Pp4wiiUruly5ODScvAwcQ&index=31

=== Controllers 

==== ReplicaSet
A ReplicaSet’s purpose is to maintain a stable set of replica Pods running at any given time. 
As such, it is often used to guarantee the availability of a specified number of identical Pods

==== Replication Controller 
A ReplicationController ensures that a specified number of pod replicas are running at any one time. 
In other words, a ReplicationController makes sure that a pod or a homogeneous set of pods is always up 
and available.

If there are too many pods, the ReplicationController terminates the extra pods. If there are too few, 
the ReplicationController starts more pods. Unlike manually created pods, the pods maintained by a 
ReplicationController are automatically replaced if they fail, are deleted, or are terminated.


==== Deployment 
A Deployment controller provides declarative updates for Pods and ReplicaSets.

You describe a desired state in a Deployment, and the Deployment controller changes the actual state to the 
desired state at a controlled rate. You can define Deployments to create new ReplicaSets, or to remove existing 
Deployments and adopt all their resources with new Deployment

Note: A Deployment that configures a ReplicaSet is now the recommended way to set up replication.


==== StatefulSets
StatefulSet is the workload API object used to manage stateful applications.
Manages the deployment and scaling of a set of Pods , and provides guarantees about the ordering and uniqueness
 of these Pods.

Like a Deployment , a StatefulSet manages Pods that are based on an identical container spec. 
Unlike a Deployment, a StatefulSet maintains a sticky identity for each of their Pods. These pods are created 
from the same spec, but are not interchangeable: each has a persistent identifier that it maintains 
across any rescheduling.



=== Advance Topics:

==== Namespace 
Namespaces are a fundamental concept to add multi-tenancy to your Kubernetes instance. 
Kubernetes provides multiple virtual clusters backed by the same physical cluster. These virtual clusters are called namespaces. 

There are four primary use cases. 
	- roles and responsibilities in an enterprise.  
	- partitioning landscapes, for example, dev vs test vs production. 
	- customer partitioning for non-multi-tenant scenarios. 
    - Application partitioning

To create namespace 
    kubectl create namespace 
    kubeclt get namespace 
    kubectl delete namespace 

==== Logging 
Once your application is running in staging or production, you might consider using a logging platform like Kibana 
with elasticsearch, with logs being shipped to them from Pods using Fluentd or Filebeat(Logstash)

//TODO - Sidecar Container Architecture 

==== Monitoring 
- Node Health
- Health of kubernetes
- Application Health (and Metrics)

For Node and Kubernets health, we can try two open source tools cAdvisor and heapster 


===== cAdvisor
cAdvisor is an open-source resource usage collector that was built for containers specifically. 
It auto-discovers all containers in the given node and collects CPU, memory, file system, and network usage statistics. 
cAdvisor also provides overall machine usage by analyzing the root container on the machine. 

===== Heapster
Heapster aggregates monitoring data across all of your nodes in your Kubernetes cluster. 
Just like in application, Heapster runs as a pod in deployment in the cluster. 
The Heapster pod queries usage information from the node's kubelets, which in turn queries 
that data from cAdvisor. Heapster groups the information by pod along with, including any relevant 
labels. 

===== Prometheus
Finally, your application might want to send application metrics. 
For example, the number of successful logins per hour. To ingest this, you can use an open-source framework called Prometheus. 
Prometheus is a time series database with a great query language that works well for application-specific metrics and also
can be used from an alerting standpoint. You can instrument your application to save application monitoring data at a slash 
metrics endpoint that Prometheus queries in a timely manner. 

===== Grafana
Prometheus, Heapster, and cAdvisor are typically linked to Grafana, 
which is an open-source tool to visualize monitoring data.


==== Authentication and Authorisation 
Two kinds of users:
- Normal Users: Human interating with the System
- Service Accounts: Accounts managed by the K8s and API

===== Popular Authentication Mode:

- Client crts 
    
    Client Certificate Authentication uses --client-ca-file=FILENAME  Option to send to the API Server 

    Reference file must contain one or more Certificate Authorities to validate client certificates 

    The common name of a client certificate is used as the user name for the request 



- Static Token Files

    Use --token-auth-file=FILE_WITH_TOKENS option on the command line.

    Token file is a CSV file with four columns: token, user name, UID, optional group names.
    Example: 12dw2e2d232,bhopal,34343,"group1,group2,group3"

- OpenID Connect 

    If you already have Open ID or Active Directory in your org, take a look at OpenID Connect Tokens.

    
- Webhook Mode 
    
    For larger orgnisation who already have OAuth could consider Webhook Tokens Option.

    The kube-apiserver calls out to a service defined by you to tell it whether a token is valid or not.

    Used commonly in scenarios where you want to integrate Kubernetes with a remote authentication service

    Most commonly Used.


===== Autherisation Mode:

- ABAC (Attribute-based access control) 


- RBAC (Role-based access control) 
    Mostly used 

- Webhook 
    
    The kube-apiserver calls out to a service defined by you to tell it whether a 
    specific action can be performed - it sends the token and the action the token is trying to perform 

    This method works great trying to integrate with a third-party authorization systes, or 
    if you want a complex set of rules


==== Production Kubernetes Deployment
Kubernetes the hard way: https://github.com/kelseyhightower/kubernetes-the-hard-way 
Hard to install k8s: https://groups.google.com/forum/#!topic/kubernetes-users/9ix65M13NNA
Kubeadm: http://blog.kubernetes.io/2016/09/how-we-made-kubernetes-easy-to-install.html
Kubernetes networks: https://kubernetes.io/docs/concepts/cluster-administration/networking/
Kops: https://github.com/kubernetes/kops
Get started with Kops: https://cloudacademy.com/blog/kubernetes-operations-with-kops/
Azure container service: https://docs.microsoft.com/en-us/azure/container-service/kubernetes/container-service-kubernetes-walkthrough
Oracle Container Engine: https://blogs.oracle.com/developers/announcing-oracle-container-engine-and-oracle-container-registry-service

Install a POD Network 
- Flanner 
- Weave not 

==== Detailed Look at NameSpace
Links for handout doc: http://blog.kubernetes.io/2016/08/kubernetes-namespaces-use-cases-insights.html
https://kubernetes.io/docs/tasks/administer-cluster/namespaces/


==== Momitoring and Logging 
Links for handout doc: 
Logging: https://theagileadmin.com/2010/08/20/logging-for-success/
Logging with kibana and elasticsearch: https://kubernetes.io/docs/tasks/debug-application-cluster/logging-elasticsearch-kibana/
Logging with fluentd, kibana and elasticsearch: https://logz.io/blog/kubernetes-log-analysis/
Fluent chart: https://github.com/kubernetes/charts/tree/master/stable/fluent-bit
Fluentd architecture: https://www.fluentd.org/architecture
ELK stack on kubernetes: https://crondev.com/elk-stack-kubernetes/
cAdvisor: https://hub.docker.com/r/google/cadvisor/
Monitoring: http://blog.kubernetes.io/2017/05/kubernetes-monitoring-guide.html
Comparing monitoring options: http://rancher.com/comparing-monitoring-options-for-docker-deployments/
Monitoring: https://sysdig.com/blog/monitoring-kubernetes-with-sysdig-cloud/
Prometheus: https://jaxenter.com/prometheus-monitoring-pros-cons-136019.html
Heapster: https://deis.com/blog/2016/monitoring-kubernetes-with-heapster/
Helm charts: https://github.com/kubernetes/charts/tree/master/stable


==== Authentication and Authorization
Kubernetes authentication: https://kubernetes.io/docs/admin/authentication/
RBAC+ABAC: http://blog.kubernetes.io/2017/04/rbac-support-in-kubernetes.html
RBAC Support: http://blog.kubernetes.io/2017/04/rbac-support-in-kubernetes.html
RBAC config: https://docs.bitnami.com/kubernetes/how-to/configure-rbac-in-your-kubernetes-cluster/
Kubernetes slack: kubernetes.slack.com
Kubernetes slack channel for auth: sig-auth



=== Tools from Cloud Native Computing Foundation (CNCF)

All the avaialbe tools can be found here 
https://landscape.cncf.io/

Instead of SOAP, REST, we can try gRPC (Google Remote Procedure Call)

==== Coordination and Service Discovery tools
Core DNS, Apache Zookeeper, etcd, airbnb Smartstack, Netflix Eureka, Container Pilot, SkyDns, 
VMVare Haret, kube-dns(plugin)
RECOMMEND ONE: Core DNS


==== Service Management 
Istio, Service Mesh, Netflix zool, Apache Thrift, Netflix Ribbon, f5, GRPC, Envoy, Linkerd
Hystrix
RECOMMEND ONE: Linkerd or Envoy


==== Application Monitoring
Prometheus, AppDynamics, Dynatrace,datadog, grafana, graphite, LightStep
RECOMMEND ONE: Prometheus

==== Logging 
fluentd, elastic, splunk, graylog, loggly, logz.io. logstash
RECOMMEND ONE: Fluentd

==== Application Tracing (Trace or Debug an application)
Jaegar, Open Tracing, Zipkin
RECOMMEND ONE: Jaegar

==== Security

===== Image Security 
Notary, tuff, aqua, openscap, anchore
RECOMMEND ONE:Clair

===== Key Management 
Vault, Spire, Knox, KeyWhiz
RECOMMEND ONE:Vault 




==== REFERENCE
https://www.katacoda.com/
https://labs.play-with-k8s.com/
https://thenewstack.io/kubernetes-vs-docker-swarm-whats-the-difference/
https://www.youtube.com/playlist?list=PLMPZQTftRCS8Pp4wiiUruly5ODScvAwcQ
https://hackernoon.com/kubernetes-vs-docker-swarm-a-comprehensive-comparison-73058543771e
https://medium.com/@sxia/why-kubernetes-needs-pod-service-and-deployment-f6c96c7d379b

